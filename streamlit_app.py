import streamlit as st
import streamlit.components.v1 as components
import pdfplumber
import pandas as pd
import io
import re
import base64
import os
import unicodedata
import traceback
from typing import List, Dict, Any
from openpyxl import load_workbook

# âœ… ä¿®æ­£: st.set_page_config() ã‚’æœ€åˆã«ç§»å‹•
st.set_page_config(
    page_title="ã€æ•°å‡ºè¡¨ã€‘PDF â†’ Excelã¸ã®å¤‰æ›",
    page_icon="./static/favicon.ico",
    layout="centered",
)

# --- Streamlit Session Stateã®åˆæœŸåŒ– ---
if 'master_df' not in st.session_state:
    master_csv_path = "å•†å“ãƒã‚¹ã‚¿ä¸€è¦§.csv"
    initial_master_df = None
    if os.path.exists(master_csv_path):
        encodings = ['utf-8-sig', 'utf-8', 'cp932', 'shift_jis', 'euc-jp', 'iso-2022-jp']
        for encoding in encodings:
            try:
                temp_df = pd.read_csv(master_csv_path, encoding=encoding)
                if not temp_df.empty:
                    initial_master_df = temp_df
                    st.success(f"æ—¢å­˜ã®ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ {encoding} ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
                    break
            except (UnicodeDecodeError, pd.errors.EmptyDataError):
                continue
            except Exception as e:
                st.warning(f"æ—¢å­˜ãƒã‚¹ã‚¿CSV ({master_csv_path}) ã‚’ {encoding} ã§èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                continue
    if initial_master_df is None:
        st.warning(f"ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ '{master_csv_path}' ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚ãƒã‚¹ã‚¿è¨­å®šãƒšãƒ¼ã‚¸ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        initial_master_df = pd.DataFrame(columns=['å•†å“äºˆå®šå', 'ãƒ‘ãƒ³ç®±å…¥æ•°'])
    st.session_state.master_df = initial_master_df

# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆExcelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
if 'template_wb_loaded' not in st.session_state:
    st.session_state.template_wb_loaded = False
    st.session_state.template_wb = None

template_path = "template.xlsm"

if not st.session_state.template_wb_loaded:
    if not os.path.exists(template_path):
        st.error(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ« '{template_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()
    
    try:
        st.session_state.template_wb = load_workbook(template_path, keep_vba=True)
        st.session_state.template_wb_loaded = True
        st.success(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ« '{template_path}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    except Exception as e:
        st.error(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ« '{template_path}' ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

# PWAç”¨HTMLåŸ‹ã‚è¾¼ã¿
components.html(
    """
    <link rel="manifest" href="./static/manifest.json">
    <link rel="icon" href="./static/favicon.ico">
    <link rel="apple-touch-icon" sizes="180x180" href="./static/icons/apple-touch-icon.png">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-title" content="PDFConverter">
    """,
    height=0,
)

# CSSã‚¹ã‚¿ã‚¤ãƒ«
# CSSã‚¹ã‚¿ã‚¤ãƒ«
st.markdown("""
    <style>
        @import url(\'https://fonts.googleapis.com/css2?family=Work+Sans:wght@300;400;500;600;700&family=Noto+Sans:wght@300;400;500;600;700&display=swap\');
        
        /* å…¨ä½“ã®ãƒ™ãƒ¼ã‚¹ã‚¹ã‚¿ã‚¤ãƒ« */
        .stApp { 
            background: #fcf8f8; 
            font-family: \'Work Sans\', \'Noto Sans\', sans-serif; 
        }
        
        /* ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ« */
        .title { 
            font-size: 2rem; 
            font-weight: 700; 
            color: #1b0f0e; 
            margin-bottom: 8px; 
            text-align: center;
            letter-spacing: -0.015em;
        }
        .subtitle { 
            font-size: 1rem; 
            color: #97524e; 
            margin-bottom: 32px; 
            text-align: center;
            font-weight: 400;
        }
        
        /* ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é ˜åŸŸã®æ”¹å–„ */
        .upload-area {
            background: white;
            border: 2px dashed #e7d1d0;
            border-radius: 12px;
            padding: 48px 24px;
            margin: 24px 0;
            text-align: center;
            transition: all 0.3s ease;
            position: relative; /* st.file_uploaderã‚’é‡ã­ã‚‹ãŸã‚ã«å¿…è¦ */
            overflow: hidden; /* ã¯ã¿å‡ºã—ã‚’éš ã™ */
        }
        .upload-area:hover {
            border-color: #ea4f47;
            background: #fefcfc;
        }
        
        /* st.file_uploader ã®è¦‹ãŸç›®ã‚’å®Œå…¨ã«éè¡¨ç¤ºã«ã—ã€ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒªã‚¢ã«é‡ã­ã‚‹ */
        .stFileUploader > div > div {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            opacity: 0; /* é€æ˜ã«ã™ã‚‹ */
            cursor: pointer;
            z-index: 10; /* ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒªã‚¢ã®ä¸Šã«é…ç½® */
        }
        /* st.file_uploader ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ©ãƒ™ãƒ«ã¨ãƒ˜ãƒ«ãƒ—ãƒ†ã‚­ã‚¹ãƒˆã‚’éè¡¨ç¤º */
        .stFileUploader label, .stFileUploader p {
            display: none !important;
        }
        
        /* ã‚«ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ« */
        .main-card { 
            background: white; 
            border-radius: 16px; 
            padding: 32px; 
            margin: 24px 0; 
            box-shadow: 0 4px 12px rgba(0,0,0,0.08);
            border: 1px solid #f3e8e7;
        }
        
        .info-card { 
            background: white; 
            border-radius: 12px; 
            padding: 20px 24px; 
            margin: 16px 0; 
            box-shadow: 0 2px 8px rgba(0,0,0,0.06);
            border: 1px solid #f3e8e7;
        }
        
        /* ãƒœã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ« */
        .stButton > button {
            background: #ea4f47 !important;
            color: white !important;
            border: none !important;
            border-radius: 8px !important;
            padding: 12px 24px !important;
            font-weight: 600 !important;
            font-size: 14px !important;
            letter-spacing: 0.015em !important;
            transition: all 0.2s ease !important;
            box-shadow: 0 2px 4px rgba(234, 79, 71, 0.2) !important;
        }
        .stButton > button:hover {
            background: #d63d35 !important;
            box-shadow: 0 4px 8px rgba(234, 79, 71, 0.3) !important;
            transform: translateY(-1px) !important;
        }
        
        /* ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒœã‚¿ãƒ³ */
        .secondary-button {
            background: #f3e8e7 !important;
            color: #1b0f0e !important;
            border: 1px solid #e7d1d0 !important;
        }
        .secondary-button:hover {
            background: #e7d1d0 !important;
        }
        
        /* ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ */
        .progress-container {
            background: #f3e8e7;
            border-radius: 8px;
            height: 8px;
            margin: 16px 0;
            overflow: hidden;
        }
        .progress-bar {
            background: #ea4f47;
            height: 100%;
            border-radius: 8px;
            transition: width 0.3s ease;
        }
        
        /* ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ãƒ”ãƒŠãƒ¼ */
        .loading-spinner { 
            width: 24px; 
            height: 24px; 
            border: 3px solid #f3e8e7; 
            border-radius: 50%; 
            border-top-color: #ea4f47; 
            animation: spin 1s linear infinite; 
            margin: 0 auto;
        }
        @keyframes spin { 
            to { transform: rotate(360deg); } 
        }
        
        /* ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º */
        .file-info {
            display: flex;
            align-items: center;
            gap: 12px;
            padding: 16px;
            background: #fefcfc;
            border: 1px solid #f3e8e7;
            border-radius: 8px;
            margin: 16px 0;
        }
        .file-icon { 
            width: 40px; 
            height: 40px; 
            border-radius: 8px; 
            background: linear-gradient(135deg, #ea4f47, #f56565); 
            display: flex; 
            align-items: center; 
            justify-content: center; 
            color: white;
            font-weight: 600;
            font-size: 14px;
        }
        
        /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®æ”¹å–„ */
        .css-1d391kg {
            background: #fefcfc !important;
        }
        
        /* æˆåŠŸãƒ»ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ”¹å–„ */
        .stSuccess {
            background: #f0f9f0 !important;
            border: 1px solid #4caf50 !important;
            border-radius: 8px !important;
            color: #2e7d32 !important;
        }
        .stError {
            background: #fef5f5 !important;
            border: 1px solid #f44336 !important;
            border-radius: 8px !important;
            color: #c62828 !important;
        }
        .stWarning {
            background: #fff8e1 !important;
            border: 1px solid #ff9800 !important;
            border-radius: 8px !important;
            color: #ef6c00 !important;
        }
        
        /* ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤ºã®æ”¹å–„ */
        .stDataFrame {
            border-radius: 8px !important;
            overflow: hidden !important;
            box-shadow: 0 2px 8px rgba(0,0,0,0.06) !important;
        }
        
        /* ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®æ”¹å–„ */
        /* st.file_uploader ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãã—ã¦ã€ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒªã‚¢ã«ãƒ•ã‚£ãƒƒãƒˆã•ã›ã‚‹ */
        .stFileUploader {
            /* Streamlitã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ä½™ç™½ã‚’ãƒªã‚»ãƒƒãƒˆ */
            margin-bottom: 0 !important;
        }
        .stFileUploader > div {
            /* Streamlitã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ä½™ç™½ã‚’ãƒªã‚»ãƒƒãƒˆ */
            margin-bottom: 0 !important;
        }
        
        /* ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¦‹å‡ºã— */
        .section-header {
            font-size: 1.25rem;
            font-weight: 600;
            color: #1b0f0e;
            margin: 32px 0 16px 0;
            padding-bottom: 8px;
            border-bottom: 2px solid #f3e8e7;
        }
        
        /* ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¤º */
        .step-indicator {
            display: flex;
            align-items: center;
            gap: 8px;
            margin: 16px 0;
            padding: 12px 16px;
            background: #fefcfc;
            border-radius: 8px;
            border-left: 4px solid #ea4f47;
        }
        .step-number {
            background: #ea4f47;
            color: white;
            width: 24px;
            height: 24px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 12px;
            font-weight: 600;
        }
    </style>
""", unsafe_allow_html=True)

def create_upload_area(title, description):
    """ã‚«ã‚¹ã‚¿ãƒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é ˜åŸŸã‚’ä½œæˆ"""
    return f"""
    <div class="upload-area">
        <div style="margin-bottom: 16px;">
            <div class="file-icon" style="margin: 0 auto 16px auto;">PDF</div>
        </div>
        <h3 style="color: #1b0f0e; font-size: 1.125rem; font-weight: 600; margin-bottom: 8px;">{title}</h3>
        <p style="color: #97524e; font-size: 0.875rem; margin-bottom: 0;">{description}</p>
    </div>
    """

def create_step_indicator(step_number, title, description):
    """ã‚¹ãƒ†ãƒƒãƒ—ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã‚’ä½œæˆ"""
    return f"""
    <div class="step-indicator">
        <div class="step-number">{step_number}</div>
        <div>
            <div style="font-weight: 600; color: #1b0f0e;">{title}</div>
            <div style="font-size: 0.875rem; color: #97524e;">{description}</div>
        </div>
    </div>
    """

def create_progress_bar(percentage):
    """ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’ä½œæˆ"""
    return f"""
    <div class="progress-container">
        <div class="progress-bar" style="width: {percentage}%;"></div>
    </div>
    <p style="text-align: center; color: #97524e; font-size: 0.875rem; margin-top: 8px;">{percentage}% å®Œäº†</p>
    """

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ ---
st.sidebar.title("ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
page_selection = st.sidebar.radio(
    "è¡¨ç¤ºã™ã‚‹æ©Ÿèƒ½ã‚’é¸æŠã—ã¦ãã ã•ã„",
    ("PDF â†’ Excel å¤‰æ›", "ãƒã‚¹ã‚¿è¨­å®š"),
    index=0
)

st.markdown("---")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è©³ç´°ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæƒ…å ±æŠ½å‡ºé–¢æ•°ç¾¤ï¼ˆçµ±åˆç‰ˆï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_detailed_client_info_from_pdf(pdf_file_obj):
    """PDFã‹ã‚‰è©³ç´°ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæƒ…å ±ï¼ˆåå‰ï¼‹çµ¦é£Ÿã®æ•°ï¼‰ã‚’æŠ½å‡ºã™ã‚‹"""
    client_data = []
    
    try:
        with pdfplumber.open(pdf_file_obj) as pdf:
            for page_num, page in enumerate(pdf.pages):
                # è¡¨å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                rows = extract_text_with_layout(page)
                if not rows:
                    continue
                
                # åœ’åã®ä½ç½®ã‚’æ¢ã™
                garden_row_idx = -1
                for i, row in enumerate(rows):
                    row_text = ''.join(str(cell) for cell in row if cell)
                    if 'åœ’å' in row_text:
                        garden_row_idx = i
                        break
                
                if garden_row_idx == -1:
                    continue
                
                # åœ’åã‚ˆã‚Šä¸‹ã®è¡Œã‚’å‡¦ç†
                current_client_id = None
                current_client_name = None
                
                for i in range(garden_row_idx + 1, len(rows)):
                    row = rows[i]
                    
                    # 10001ãŒå‡ºã¦ããŸã‚‰çµ‚äº†
                    row_text = ''.join(str(cell) for cell in row if cell)
                    if '10001' in row_text:
                        break
                    
                    # ç©ºè¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
                    if not any(str(cell).strip() for cell in row):
                        continue
                    
                    # å·¦ã®åˆ—ï¼ˆ1ç•ªç›®ã®åˆ—ï¼‰ã‚’ãƒã‚§ãƒƒã‚¯
                    if len(row) > 0 and row[0]:
                        left_cell = str(row[0]).strip()
                        
                        # æ•°å­—ã ã‘ã®å ´åˆã¯ID
                        if re.match(r'^\d+$', left_cell):
                            # å‰ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                            if current_client_id and current_client_name:
                                client_info = extract_meal_numbers_from_row(rows, i-1, current_client_id, current_client_name)
                                if client_info:
                                    client_data.append(client_info)
                            
                            current_client_id = left_cell
                            current_client_name = None
                        
                        # æ•°å­—ä»¥å¤–ã®å ´åˆã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå
                        elif not re.match(r'^\d+$', left_cell) and current_client_id:
                            current_client_name = left_cell
                
                # æœ€å¾Œã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                if current_client_id and current_client_name:
                    client_info = extract_meal_numbers_from_row(rows, len(rows)-1, current_client_id, current_client_name)
                    if client_info:
                        client_data.append(client_info)
    
    except Exception as e:
        st.error(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæƒ…å ±æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    return client_data

def extract_meal_numbers_from_row(rows, row_idx, client_id, client_name):
    """æŒ‡å®šã•ã‚ŒãŸè¡Œã¨ãã®å‘¨è¾ºã‹ã‚‰çµ¦é£Ÿã®æ•°ã‚’æŠ½å‡º"""
    client_info = {
        'client_id': client_id,
        'client_name': client_name,
        'student_meals': [],
        'teacher_meals': []
    }
    
    # IDã®è¡Œã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåã®è¡Œã‹ã‚‰æ•°å­—ã‚’æŠ½å‡º
    rows_to_check = []
    
    # IDã®è¡Œã‚’æ¢ã™
    id_row_idx = -1
    name_row_idx = -1
    
    for i in range(max(0, row_idx - 3), min(len(rows), row_idx + 3)):
        if i < len(rows) and len(rows[i]) > 0:
            left_cell = str(rows[i][0]).strip()
            if left_cell == client_id:
                id_row_idx = i
                rows_to_check.append(('id', i, rows[i]))
            elif left_cell == client_name:
                name_row_idx = i
                rows_to_check.append(('name', i, rows[i]))
    
    # æ•°å­—ã‚’æŠ½å‡º
    all_numbers = []
    
    for row_type, idx, row in rows_to_check:
        # å·¦ã®åˆ—ï¼ˆ0ç•ªç›®ï¼‰ä»¥å¤–ã®åˆ—ã‹ã‚‰æ•°å­—ã‚’æŠ½å‡º
        for col_idx in range(1, len(row)):
            cell = str(row[col_idx]).strip()
            if cell and re.match(r'^\d+$', cell):
                all_numbers.append({
                    'number': int(cell),
                    'row_type': row_type,
                    'col_idx': col_idx
                })
            elif cell and not re.match(r'^\d+$', cell) and cell != '':
                # æ•°å­—ä»¥å¤–ã®æ–‡å­—ãŒå‡ºã¦ããŸã‚‰ãã®è¡Œã¯ã“ã“ã§çµ‚äº†
                break
    
    # åœ’å…ã®çµ¦é£Ÿã®æ•°ã¨å…ˆç”Ÿã®çµ¦é£Ÿã®æ•°ã«åˆ†ã‘ã‚‹
    # IDã®è¡Œã®æ•°å­—ã¯åœ’å…ã®çµ¦é£Ÿã®æ•°
    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåã®è¡Œã®æ•°å­—ã¯å…ˆç”Ÿã®çµ¦é£Ÿã®æ•°
    
    id_numbers = [item['number'] for item in all_numbers if item['row_type'] == 'id']
    name_numbers = [item['number'] for item in all_numbers if item['row_type'] == 'name']
    
    # åœ’å…ã®çµ¦é£Ÿã®æ•°ï¼ˆæœ€å¤§3ã¤ï¼‰
    client_info['student_meals'] = id_numbers[:3]
    
    # å…ˆç”Ÿã®çµ¦é£Ÿã®æ•°ï¼ˆæœ€å¤§2ã¤ï¼‰
    client_info['teacher_meals'] = name_numbers[:2]
    
    return client_info

def export_detailed_client_data_to_dataframe(client_data):
    """è©³ç´°ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæƒ…å ±ã‚’DataFrameã«å¤‰æ›"""
    df_data = []
    
    for client_info in client_data:
        row = {
            'ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå': client_info['client_name'],
            'åœ’å…ã®çµ¦é£Ÿã®æ•°1': client_info['student_meals'][0] if len(client_info['student_meals']) > 0 else '',
            'åœ’å…ã®çµ¦é£Ÿã®æ•°2': client_info['student_meals'][1] if len(client_info['student_meals']) > 1 else '',
            'åœ’å…ã®çµ¦é£Ÿã®æ•°3': client_info['student_meals'][2] if len(client_info['student_meals']) > 2 else '',
            'å…ˆç”Ÿã®çµ¦é£Ÿã®æ•°1': client_info['teacher_meals'][0] if len(client_info['teacher_meals']) > 0 else '',
            'å…ˆç”Ÿã®çµ¦é£Ÿã®æ•°2': client_info['teacher_meals'][1] if len(client_info['teacher_meals']) > 1 else '',
        }
        df_data.append(row)
    
    return pd.DataFrame(df_data)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ—¢å­˜ã®PDFâ†’Excelå¤‰æ›é–¢æ•°ç¾¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def is_number(text: str) -> bool:
    return bool(re.match(r'^\d+$', text.strip()))

def get_line_groups(words: List[Dict[str, Any]], y_tolerance: float = 1.2) -> List[List[Dict[str, Any]]]:
    if not words:
        return []
    sorted_words = sorted(words, key=lambda w: w['top'])
    groups = []
    current_group = [sorted_words[0]]
    current_top = sorted_words[0]['top']
    for word in sorted_words[1:]:
        if abs(word['top'] - current_top) <= y_tolerance:
            current_group.append(word)
        else:
            groups.append(current_group)
            current_group = [word]
            current_top = word['top']
    groups.append(current_group)
    return groups

def get_vertical_boundaries(page, tolerance: float = 2) -> List[float]:
    vertical_lines_x = []
    for line in page.lines:
        if abs(line['x0'] - line['x1']) < tolerance:
            vertical_lines_x.append((line['x0'] + line['x1']) / 2)
    vertical_lines_x = sorted(list(set(round(x, 1) for x in vertical_lines_x)))

    words = page.extract_words()
    if not words:
        return vertical_lines_x

    left_boundary = min(word['x0'] for word in words)
    right_boundary = max(word['x1'] for word in words)

    boundaries = sorted(list(set([round(left_boundary, 1)] + vertical_lines_x + [round(right_boundary, 1)])))

    merged_boundaries = []
    if boundaries:
        merged_boundaries.append(boundaries[0])
        for i in range(1, len(boundaries)):
            if boundaries[i] - merged_boundaries[-1] > tolerance * 2:
                merged_boundaries.append(boundaries[i])
        if right_boundary > merged_boundaries[-1] + tolerance * 2:
            merged_boundaries.append(round(right_boundary, 1))
        boundaries = sorted(list(set(merged_boundaries)))

    return boundaries

def split_line_using_boundaries(sorted_words_in_line: List[Dict[str, Any]], boundaries: List[float]) -> List[str]:
    columns = [""] * (len(boundaries) - 1)
    for word in sorted_words_in_line:
        word_center_x = (word['x0'] + word['x1']) / 2
        for i in range(len(boundaries) - 1):
            left = boundaries[i]
            right = boundaries[i + 1]
            if left <= word_center_x < right:
                if columns[i]:
                    columns[i] += " " + word["text"]
                else:
                    columns[i] = word["text"]
                break
    return columns

def extract_text_with_layout(page) -> List[List[str]]:
    words = page.extract_words(x_tolerance=3, y_tolerance=3, keep_blank_chars=False)
    if not words:
        return []

    boundaries = get_vertical_boundaries(page)
    if len(boundaries) < 2:
        lines = page.extract_text(layout=False, x_tolerance=3, y_tolerance=3)
        return [[line] for line in lines.split('\n') if line.strip()]

    row_groups = get_line_groups(words, y_tolerance=1.5)

    result_rows = []
    for group in row_groups:
        sorted_group = sorted(group, key=lambda w: w['x0'])
        columns = split_line_using_boundaries(sorted_group, boundaries)
        if any(cell.strip() for cell in columns):
            result_rows.append(columns)

    return result_rows

def remove_extra_empty_columns(rows: List[List[str]]) -> List[List[str]]:
    if not rows:
        return rows
    num_cols = max(len(row) for row in rows) if rows else 0
    if num_cols == 0:
        return rows

    is_col_empty = [True] * num_cols
    for r, row in enumerate(rows):
        for c in range(len(row)):
            if c < num_cols and row[c].strip():
                is_col_empty[c] = False

    keep_indices = [c for c in range(num_cols) if not is_col_empty[c]]

    new_rows = []
    for row in rows:
        new_row = [row[i] if i < len(row) else "" for i in keep_indices]
        new_rows.append(new_row)

    return new_rows

def post_process_rows(rows: List[List[str]]) -> List[List[str]]:
    new_rows = [row[:] for row in rows]
    for i, row in enumerate(new_rows):
        for j, cell in enumerate(row):
            if "åˆè¨ˆ" in str(cell):
                if i > 0 and j < len(new_rows[i-1]):
                    new_rows[i-1][j] = ""
    return new_rows

def pdf_to_excel_data_for_paste_sheet(pdf_file) -> pd.DataFrame | None:
    try:
        with pdfplumber.open(pdf_file) as pdf:
            if not pdf.pages:
                st.warning("PDFã«ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                return None
            page = pdf.pages[0]

            rows = extract_text_with_layout(page)
            rows = [row for row in rows if any(cell.strip() for cell in row)]
            if not rows:
                st.warning("PDFã®æœ€åˆã®ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                return None

            rows = post_process_rows(rows)
            rows = remove_extra_empty_columns(rows)
            if not rows or not rows[0]:
                st.warning("ç©ºã®åˆ—ã‚’å‰Šé™¤ã—ãŸçµæœã€ãƒ‡ãƒ¼ã‚¿ãŒãªããªã‚Šã¾ã—ãŸã€‚")
                return None

            max_cols = max(len(row) for row in rows) if rows else 0
            normalized_rows = [row + [''] * (max_cols - len(row)) for row in rows]
            df = pd.DataFrame(normalized_rows)
            return df

    except Exception as e:
        st.error(f"PDFå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def extract_table_from_pdf_for_bento(pdf_file_obj):
    tables = []
    with pdfplumber.open(pdf_file_obj) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            
            start_keywords = ["åœ’å", "é£¯ã‚ã‚Š", "ã‚­ãƒ£ãƒ©å¼"]
            end_keywords = ["ãŠã‚„ã¤", "åˆè¨ˆ", "PAGE"]
            
            if not any(kw in text for kw in start_keywords):
                continue
                
            lines = page.lines
            if not lines:
                continue
                
            y_coords = sorted(set([line['top'] for line in lines] + [line['bottom'] for line in lines]))
            if len(y_coords) < 2:
                continue
                
            table_top = min(y_coords)
            table_bottom = max(y_coords)
            
            x_coords = sorted(set([line['x0'] for line in lines] + [line['x1'] for line in lines]))
            if len(x_coords) < 2:
                continue
                
            table_left = min(x_coords)
            table_right = max(x_coords)
            
            table_bbox = (table_left, table_top, table_right, table_bottom)
            cropped_page = page.crop(table_bbox)
            
            table_settings = {
                "vertical_strategy": "lines",
                "horizontal_strategy": "lines",
                "snap_tolerance": 3,
                "join_tolerance": 3,
                "edge_min_length": 15,
            }
            
            table = cropped_page.extract_table(table_settings)
            if table:
                tables.append(table)
    
    return tables

def find_correct_anchor_for_bento(table, target_row_text="èµ¤"):
    for row_idx, row in enumerate(table):
        row_text = ''.join(str(cell) for cell in row if cell)
        if target_row_text in row_text:
            for offset in [1, 2]:
                if row_idx + offset < len(table):
                    next_row = table[row_idx + offset]
                    for col_idx, cell in enumerate(next_row):
                        if cell and "é£¯ãªã—" in cell:
                            return col_idx
    return -1

def extract_bento_range_for_bento(table, start_col):
    bento_list = []
    end_col = -1
    
    for row in table:
        row_text = ''.join(str(cell) for cell in row if cell)
        if "ãŠã‚„ã¤" in row_text:
            for col_idx, cell in enumerate(row):
                if cell and "ãŠã‚„ã¤" in cell:
                    end_col = col_idx
                    break
            if end_col != -1:
                break
    
    if end_col == -1 or start_col >= end_col:
        return []
    
    header_row_idx = None
    anchor_row_idx = -1
    for row_idx, row in enumerate(table):
        if any(cell and "é£¯ãªã—" in cell for cell in row):
            anchor_row_idx = row_idx
            break
    
    if anchor_row_idx == -1:
        return []
    
    if anchor_row_idx - 1 >= 0:
        header_row_idx = anchor_row_idx - 1
    else:
        return []
    
    for col in range(start_col + 1, end_col + 1):
        if col < len(table[header_row_idx]):
            cell_text = table[header_row_idx][col]
        else:
            cell_text = ""
        
        if cell_text and str(cell_text).strip() and "é£¯ãªã—" not in str(cell_text):
            bento_list.append(str(cell_text).strip())
    
    return bento_list

def match_bento_names(pdf_bento_list, master_df):
    if master_df is None or master_df.empty:
        st.error("ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return [f"{name} (ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ãªã—)" for name in pdf_bento_list]

    master_data_tuples = []
    try:
        if 'å•†å“äºˆå®šå' in master_df.columns and 'ãƒ‘ãƒ³ç®±å…¥æ•°' in master_df.columns:
            master_data_tuples = master_df[['å•†å“äºˆå®šå', 'ãƒ‘ãƒ³ç®±å…¥æ•°']].dropna().values.tolist()
            master_data_tuples = [(str(name), str(value)) for name, value in master_data_tuples]
        elif 'å•†å“äºˆå®šå' in master_df.columns:
            st.warning("ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ã€Œãƒ‘ãƒ³ç®±å…¥æ•°ã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            master_data_tuples = master_df['å•†å“äºˆå®šå'].dropna().astype(str).tolist()
            master_data_tuples = [(name, "") for name in master_data_tuples]
        else:
            st.error("ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ã€Œå•†å“äºˆå®šåã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return [f"{name} (å•†å“äºˆå®šååˆ—ãªã—)" for name in pdf_bento_list]

    except Exception as e:
        st.error(f"ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return [f"{name} (å‡¦ç†ã‚¨ãƒ©ãƒ¼)" for name in pdf_bento_list]
    
    if len(master_data_tuples) == 0:
        st.warning("ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ‰åŠ¹ãªå•†å“æƒ…å ±ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return [f"{name} (ãƒã‚¹ã‚¿ç©º)" for name in pdf_bento_list]

    matched = []
    
    normalized_master_data_tuples = []
    for master_name, master_id in master_data_tuples:
        normalized_name = unicodedata.normalize('NFKC', master_name)
        normalized_name = re.sub(r'\s+', '', normalized_name)
        normalized_master_data_tuples.append((normalized_name, master_name, master_id))
    
    for pdf_name in pdf_bento_list:
        original_normalized_pdf_name = unicodedata.normalize('NFKC', str(pdf_name))
        original_normalized_pdf_name = re.sub(r'\s+', '', original_normalized_pdf_name)
        
        found_match = False
        found_original_master_name = None
        found_id = None
        
        for norm_m_name, orig_m_name, m_id in normalized_master_data_tuples:
            if norm_m_name.startswith(original_normalized_pdf_name):
                found_original_master_name = orig_m_name
                found_id = m_id
                found_match = True
                break
        
        if not found_match:
            for norm_m_name, orig_m_name, m_id in normalized_master_data_tuples:
                if original_normalized_pdf_name in norm_m_name:
                    found_original_master_name = orig_m_name
                    found_id = m_id
                    found_match = True
                    break
        
        if not found_match:
            for num_chars_to_remove in range(1, 4):
                if len(original_normalized_pdf_name) > num_chars_to_remove:
                    truncated_pdf_name = original_normalized_pdf_name[:-num_chars_to_remove]
                    
                    for norm_m_name, orig_m_name, m_id in normalized_master_data_tuples:
                        if norm_m_name.startswith(truncated_pdf_name):
                            found_original_master_name = orig_m_name
                            found_id = m_id
                            found_match = True
                            break
                    
                    if not found_match:
                        for norm_m_name, orig_m_name, m_id in normalized_master_data_tuples:
                            if truncated_pdf_name in norm_m_name:
                                found_original_master_name = orig_m_name
                                found_id = m_id
                                found_match = True
                                break
                    
                    if found_match:
                        break
        
        if found_original_master_name:
            if found_id:
                matched.append(f"{found_original_master_name} (å…¥æ•°: {found_id})")
            else:
                matched.append(found_original_master_name)
        else:
            matched.append(f"{pdf_name} (æœªãƒãƒƒãƒ)")
    
    return matched

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# PDF â†’ Excel å¤‰æ› ãƒšãƒ¼ã‚¸
if page_selection == "PDF â†’ Excel å¤‰æ›":
    st.markdown(\'<div class="title">ã€æ•°å‡ºè¡¨ã€‘PDF â†’ Excelã¸ã®å¤‰æ›</div>\', unsafe_allow_html=True)
    st.markdown(\'<div class="subtitle">PDFã®æ•°å‡ºè¡¨ã‚’Excelã«å¤‰æ›ã—ã€è©³ç´°ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæƒ…å ±ã‚‚å«ã‚ã¦ä¸€æ‹¬å‡¦ç†ã—ã¾ã™ã€‚</div>\', unsafe_allow_html=True)

    # ã‚«ã‚¹ã‚¿ãƒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é ˜åŸŸã®è¡¨ç¤º
    # st.file_uploader ã‚’ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒªã‚¢ã®ä¸­ã«é…ç½®ã—ã€label_visibility="hidden" ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ©ãƒ™ãƒ«ã‚’éè¡¨ç¤ºã«ã™ã‚‹
    # ã“ã‚Œã«ã‚ˆã‚Šã€ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒªã‚¢ãŒã‚¯ãƒªãƒƒã‚¯å¯èƒ½ã«ãªã‚Šã€ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°ãŒé–‹ã
    with st.container():
        st.markdown(create_upload_area(
            "PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—", 
            "ã¾ãŸã¯ã“ã“ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
        ), unsafe_allow_html=True)
        uploaded_pdf = st.file_uploader("", type="pdf", label_visibility="hidden")

    if uploaded_pdf is not None and st.session_state.template_wb is not None:
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
        file_ext = uploaded_pdf.name.split(\".\")[-1].upper()
        file_size = len(uploaded_pdf.getvalue()) / 1024
        
        st.markdown(f"""
        <div class="file-info">
            <div class="file-icon">{file_ext}</div>
            <div>
                <div style="font-weight: 600; color: #1b0f0e;">{uploaded_pdf.name}</div>
                <div style="font-size: 0.875rem; color: #97524e;">ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.1f} KB</div>
            </div>
        </div>
        """, unsafe_allow_html=True)

        # PDFã®ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’io.BytesIOã«å¤‰æ›
        pdf_bytes_io = io.BytesIO(uploaded_pdf.getvalue())

        # å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã®è¡¨ç¤º
        st.markdown(create_step_indicator(1, "è²¼ã‚Šä»˜ã‘ç”¨ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º", "PDFã‹ã‚‰åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦ã„ã¾ã™"), unsafe_allow_html=True)
        
        # 1. è²¼ã‚Šä»˜ã‘ç”¨ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
        df_paste_sheet = None
        with st.spinner("ã€Œè²¼ã‚Šä»˜ã‘ç”¨ã€ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºä¸­..."):
            pdf_bytes_io.seek(0)
            df_paste_sheet = pdf_to_excel_data_for_paste_sheet(pdf_bytes_io)

        if df_paste_sheet is not None:
            st.markdown(create_progress_bar(33), unsafe_allow_html=True)
            
            st.markdown(create_step_indicator(2, "æ³¨æ–‡å¼å½“ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º", "å¼å½“æƒ…å ±ã‚’ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ç…§åˆã—ã¦ã„ã¾ã™"), unsafe_allow_html=True)
            
        # 2. æ³¨æ–‡å¼å½“ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
        df_bento_sheet = None
        if df_paste_sheet is not None:
            with st.spinner("ã€Œæ³¨æ–‡å¼å½“ã®æŠ½å‡ºã€ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºä¸­..."):
                try:
                    pdf_bytes_io.seek(0)
                    tables = extract_table_from_pdf_for_bento(pdf_bytes_io)
                    if tables:
                        main_table = max(tables, key=lambda t: len(t) * len(t[0]))
                        if main_table:
                            anchor_col = find_correct_anchor_for_bento(main_table)
                            if anchor_col != -1:
                                bento_list = extract_bento_range_for_bento(main_table, anchor_col)
                                if bento_list:
                                    matched_list = match_bento_names(bento_list, st.session_state.master_df)
                                    output_data_bento = []
                                    for item in matched_list:
                                        match = re.search(r' \(å…¥æ•°: (.+?)\)$', item)
                                        if match:
                                            bento_name = item[:match.start()]
                                            bento_count = match.group(1)
                                            output_data_bento.append([bento_name.strip(), bento_count.strip()])
                                        elif "(æœªãƒãƒƒãƒ)" in item:
                                            bento_name = item.replace(" (æœªãƒãƒƒãƒ)", "").strip()
                                            output_data_bento.append([bento_name, ""])
                                        else:
                                            output_data_bento.append([item.strip(), ""])
                                    df_bento_sheet = pd.DataFrame(output_data_bento, columns=['å•†å“äºˆå®šå', 'ãƒ‘ãƒ³ç®±å…¥æ•°'])
                except Exception as e:
                    st.error(f"æ³¨æ–‡å¼å½“ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        # 3. è©³ç´°ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæƒ…å ±ã®æŠ½å‡º
        df_client_sheet = None
        if df_paste_sheet is not None:
            with st.spinner("ã€Œã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæŠ½å‡ºã€ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºä¸­..."):
                try:
                    pdf_bytes_io.seek(0)
                    client_data = extract_detailed_client_info_from_pdf(pdf_bytes_io)
                    if client_data:
                        df_client_sheet = export_detailed_client_data_to_dataframe(client_data)
                        st.success(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæƒ…å ± {len(client_data)} ä»¶ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
                    else:
                        st.warning("ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæƒ…å ±ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                except Exception as e:
                    st.error(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæƒ…å ±æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        # 4. Excelãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®æ›¸ãè¾¼ã¿
        if df_paste_sheet is not None:
            try:
                with st.spinner("Excelãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿ä¸­..."):
                    # è²¼ã‚Šä»˜ã‘ç”¨ã‚·ãƒ¼ãƒˆã¸ã®æ›¸ãè¾¼ã¿
                    try:
                        ws_paste = st.session_state.template_wb["è²¼ã‚Šä»˜ã‘ç”¨"]
                        for r_idx, row in df_paste_sheet.iterrows():
                            for c_idx, value in enumerate(row):
                                ws_paste.cell(row=r_idx + 1, column=c_idx + 1, value=value)
                    except KeyError:
                        st.error("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ã€Œè²¼ã‚Šä»˜ã‘ç”¨ã€ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                        st.stop()
                    
                    # æ³¨æ–‡å¼å½“ã‚·ãƒ¼ãƒˆã¸ã®æ›¸ãè¾¼ã¿
                    if df_bento_sheet is not None and not df_bento_sheet.empty:
                        try:
                            ws_bento = st.session_state.template_wb["æ³¨æ–‡å¼å½“ã®æŠ½å‡º"]
                            for r_idx, row in df_bento_sheet.iterrows():
                                for c_idx, value in enumerate(row):
                                    ws_bento.cell(row=r_idx + 1, column=c_idx + 1, value=value)
                        except KeyError:
                            st.error("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ã€Œæ³¨æ–‡å¼å½“ã®æŠ½å‡ºã€ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

                    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæŠ½å‡ºã‚·ãƒ¼ãƒˆã¸ã®æ›¸ãè¾¼ã¿
                    if df_client_sheet is not None and not df_client_sheet.empty:
                        try:
                            ws_client = st.session_state.template_wb["ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæŠ½å‡º"]
                            for r_idx, row in df_client_sheet.iterrows():
                                for c_idx, value in enumerate(row):
                                    ws_client.cell(row=r_idx + 1, column=c_idx + 1, value=value)
                        except KeyError:
                            st.error("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ã€Œã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæŠ½å‡ºã€ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

                # 5. Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ
                with st.spinner("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆä¸­..."):
                    output = io.BytesIO()
                    st.session_state.template_wb.save(output)
                    output.seek(0)
                    final_excel_bytes = output.read()

                # 6. å‡¦ç†å®Œäº†ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                st.markdown(create_progress_bar(100), unsafe_allow_html=True)
            
                # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’æ”¹å–„ã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ã§è¡¨ç¤º
                st.markdown(\'<div class="main-card">\', unsafe_allow_html=True)
                st.success("âœ… å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                
                original_pdf_name = os.path.splitext(uploaded_pdf.name)[0]
                output_filename = f"{original_pdf_name}_Processed.xlsm"
                excel_size = len(final_excel_bytes) / 1024
                
                st.download_button(
                    label="ğŸ“¥ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=final_excel_bytes,
                    file_name=output_filename,
                    mime="application/vnd.ms-excel.sheet.macroEnabled.12",
                    help="å‡¦ç†ã•ã‚ŒãŸExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™"
                )
                
                st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {excel_size:.1f} KB")

            except Exception as e:
                st.error(f"Excelãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.markdown('</div>', unsafe_allow_html=True)

# ãƒã‚¹ã‚¿è¨­å®š ãƒšãƒ¼ã‚¸
elif page_selection == "ãƒã‚¹ã‚¿è¨­å®š":
    st.markdown('<div class="title">ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿è¨­å®š</div>', unsafe_allow_html=True)
    st.markdown('<div class="subtitle">å•†å“ãƒã‚¹ã‚¿ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦æ›´æ–°ã—ã¾ã™ã€‚</div>', unsafe_allow_html=True)

    master_csv_path = "å•†å“ãƒã‚¹ã‚¿ä¸€è¦§.csv"

    st.markdown("#### æ–°ã—ã„ãƒã‚¹ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_master_csv = st.file_uploader(
        "å•†å“ãƒã‚¹ã‚¿ä¸€è¦§.csv ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type="csv",
        help="ãƒ˜ãƒƒãƒ€ãƒ¼ã«ã¯ 'å•†å“äºˆå®šå' ã¨ 'ãƒ‘ãƒ³ç®±å…¥æ•°' ã‚’å«ã‚ã¦ãã ã•ã„ã€‚"
    )

    if uploaded_master_csv is not None:
        try:
            new_master_df = None
            encodings = ['utf-8-sig', 'utf-8', 'cp932', 'shift_jis']
            
            for encoding in encodings:
                try:
                    uploaded_master_csv.seek(0)
                    temp_df = pd.read_csv(uploaded_master_csv, encoding=encoding)
                    if 'å•†å“äºˆå®šå' in temp_df.columns and 'ãƒ‘ãƒ³ç®±å…¥æ•°' in temp_df.columns:
                        new_master_df = temp_df
                        st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ {encoding} ã§èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
                        break
                    else:
                        st.warning(f"{encoding} ã§èª­ã¿è¾¼ã¿ã¾ã—ãŸãŒã€å¿…é ˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                except (UnicodeDecodeError, pd.errors.ParserError):
                    continue
                except Exception as e:
                    st.error(f"èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                    break

            if new_master_df is not None:
                st.session_state.master_df = new_master_df
                
                try:
                    new_master_df.to_csv(master_csv_path, index=False, encoding='utf-8-sig')
                    st.success(f"âœ… ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã—ã€'{master_csv_path}' ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
                except Exception as e:
                    st.error(f"ãƒã‚¹ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£ã—ãèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")

        except Exception as e:
            st.error(f"ãƒã‚¹ã‚¿æ›´æ–°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    st.markdown("#### ç¾åœ¨ã®ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿")
    if 'master_df' in st.session_state and not st.session_state.master_df.empty:
        st.dataframe(st.session_state.master_df, use_container_width=True)
    else:
        st.warning("ç¾åœ¨ã€ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
